{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex_2b.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBiPH8i1z15Z"
      },
      "source": [
        "##Exercise 2b\r\n",
        "###Multilayer Perceptron \r\n",
        "####One hidden layer with backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2l7veWniVNS"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "import random"
      ],
      "execution_count": 1189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_P5o5zSifen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f8a428-b5d2-4cda-d93d-29293af2e021"
      },
      "source": [
        "iris = pd.read_csv(\"iris.csv\")\r\n",
        "random.seed(6)\r\n",
        "iris = iris.sample(frac=1,random_state=5).reset_index(drop=True) \r\n",
        "\r\n",
        "print (\"Random number with seed 6\")\r\n",
        "random.seed(6)"
      ],
      "execution_count": 1190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random number with seed 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mon7vvjDiqRj"
      },
      "source": [
        "X = iris[['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']]\r\n",
        "X = np.array(X)"
      ],
      "execution_count": 1191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22BiELzdi_id"
      },
      "source": [
        "\r\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\r\n",
        "Y = iris.Species\r\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\r\n"
      ],
      "execution_count": 1192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Fq1bS_jZI_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\r\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": 1193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUvtS9s9ke6N"
      },
      "source": [
        "def InitializeWeights(nodes):\r\n",
        "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\r\n",
        "    np.random.seed(6)\r\n",
        "    layers, weights = len(nodes), []\r\n",
        "    \r\n",
        "    for i in range(1, layers):\r\n",
        "        np.random.seed(6)\r\n",
        "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\r\n",
        "              for j in range(nodes[i])]\r\n",
        "        weights.append(np.matrix(w))\r\n",
        "    print(weights)\r\n",
        "    return weights"
      ],
      "execution_count": 1194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTB80UTnlgHa"
      },
      "source": [
        "def Sigmoid(x):\r\n",
        "    return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "def SigmoidDerivative(x):\r\n",
        "    return np.multiply(x, 1-x)"
      ],
      "execution_count": 1195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De-8--Nnlk-d"
      },
      "source": [
        "def ForwardPropagation(x, weights, layers):\r\n",
        "    activations, layer_input = [x], x #initializing with the input\r\n",
        "    #in every iteration of j layer_input is the sigmoid of the previous layer\r\n",
        "    for j in range(layers):\r\n",
        "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\r\n",
        "        activations.append(activation)\r\n",
        "        layer_input = np.append(1, activation) # Augment with bias\r\n",
        "    \r\n",
        "    return activations"
      ],
      "execution_count": 1196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr2wl0VFmmOz"
      },
      "source": [
        "def BackPropagation(y, activations, weights, layers):\r\n",
        "    outputFinal = activations[-1]\r\n",
        "    error = np.matrix(y - outputFinal) # Error at output\r\n",
        "    #backprop layers from last to first\r\n",
        "    for j in range(layers, 0, -1):\r\n",
        "        currActivation = activations[j]\r\n",
        "        \r\n",
        "        if(j > 1):\r\n",
        "            # Augment previous activation\r\n",
        "            prevActivation = np.append(1, activations[j-1])\r\n",
        "        else:\r\n",
        "            # First hidden layer, prevActivation is input (without bias)\r\n",
        "            prevActivation = activations[0]\r\n",
        "        \r\n",
        "        delta = np.multiply(error, SigmoidDerivative(currActivation))\r\n",
        "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\r\n",
        "\r\n",
        "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\r\n",
        "        error = np.dot(delta, w) # Calculate error for current layer\r\n",
        "    \r\n",
        "    return weights"
      ],
      "execution_count": 1197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwHcznHimo3n"
      },
      "source": [
        "def Train(X, Y, lr, weights):\r\n",
        "    layers = len(weights)\r\n",
        "    for i in range(len(X)):\r\n",
        "        x, y = X[i], Y[i]\r\n",
        "        x = np.matrix(np.append(1, x)) # Augment feature vector\r\n",
        "        \r\n",
        "        activations = ForwardPropagation(x, weights, layers)\r\n",
        "        weights = BackPropagation(y, activations, weights, layers)\r\n",
        "\r\n",
        "    return weights"
      ],
      "execution_count": 1198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQrsNZ_NmuO5"
      },
      "source": [
        "def Predict(item, weights):\r\n",
        "    layers = len(weights)\r\n",
        "    item = np.append(1, item) # Augment feature vector\r\n",
        "    \r\n",
        "    ##_Forward Propagation_##\r\n",
        "    activations = ForwardPropagation(item, weights, layers)\r\n",
        "    \r\n",
        "    outputFinal = activations[-1].A1\r\n",
        "    index = FindMaxActivation(outputFinal)\r\n",
        "\r\n",
        "    # Initialize prediction vector to zeros\r\n",
        "    y = [0 for i in range(len(outputFinal))]\r\n",
        "    y[index] = 1  # Set guessed class to 1\r\n",
        "\r\n",
        "    return y # Return prediction vector\r\n",
        "\r\n",
        "\r\n",
        "def FindMaxActivation(output):\r\n",
        "    \"\"\"Find max activation in output\"\"\"\r\n",
        "    m, index = output[0], 0\r\n",
        "    for i in range(1, len(output)):\r\n",
        "        if(output[i] > m):\r\n",
        "            m, index = output[i], i\r\n",
        "    \r\n",
        "    return index"
      ],
      "execution_count": 1199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t35SAhVmwZq"
      },
      "source": [
        "def Accuracy(X, Y, weights):\r\n",
        "    \"\"\"Run set through network, find overall accuracy\"\"\"\r\n",
        "    correct = 0\r\n",
        "\r\n",
        "    for i in range(len(X)):\r\n",
        "        x, y = X[i], list(Y[i])\r\n",
        "        guess = Predict(x, weights)\r\n",
        "\r\n",
        "        if(y == guess):\r\n",
        "            # Guessed correctly\r\n",
        "            correct += 1\r\n",
        "\r\n",
        "    return correct / len(X)"
      ],
      "execution_count": 1200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0uOtOjHjfBt"
      },
      "source": [
        "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\r\n",
        "    hidden_layers = len(nodes) - 1\r\n",
        "    weights = InitializeWeights(nodes)\r\n",
        "\r\n",
        "    for epoch in range(1, epochs+1):\r\n",
        "        weights = Train(X_train, Y_train, lr, weights)\r\n",
        "\r\n",
        "        if(epoch % 5 == 0):\r\n",
        "            print(\"Epoch {}\".format(epoch))\r\n",
        "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\r\n",
        "            if X_val.any():\r\n",
        "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\r\n",
        "            if Accuracy(X_val, Y_val, weights)>0.93:\r\n",
        "              break\r\n",
        "    return weights"
      ],
      "execution_count": 1201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVGkgicjmzed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d11553f-5b13-453b-ea54-a84f9dc611a5"
      },
      "source": [
        "f = len(X[0]) # Number of features\r\n",
        "o = len(Y[0]) # Number of outputs / classes\r\n",
        "\r\n",
        "layers = [f, 10, o] # Number of nodes in layers\r\n",
        "lr, epochs = 0.1, 20\r\n",
        "\r\n",
        "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);"
      ],
      "execution_count": 1202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[matrix([[ 0.7857203 , -0.33604039,  0.64245825, -0.91660675, -0.78468664],\n",
            "        [ 0.19010413,  0.05963472, -0.16238514, -0.3291843 ,  0.24503886],\n",
            "        [-0.12371715,  0.47176421,  0.03607282,  0.1577172 ,  0.29071019],\n",
            "        [ 0.98044854,  0.63971639, -0.17359813,  0.75253531,  0.64751887],\n",
            "        [-0.89105098,  0.43727447,  0.60434112,  0.47281329,  0.4182635 ],\n",
            "        [ 0.08187371, -0.75035165,  0.91529459, -0.1934874 , -0.56609768],\n",
            "        [ 0.43455169,  0.98841488, -0.48877189,  0.34261886,  0.19801183],\n",
            "        [ 0.43466429,  0.87469907, -0.29638046, -0.49273181, -0.19505498],\n",
            "        [ 0.49302143,  0.44814113, -0.18778441,  0.9787597 , -0.09900144],\n",
            "        [-0.25238313,  0.41925721, -0.83508289, -0.20325416,  0.54176193]]), matrix([[ 0.7857203 , -0.33604039,  0.64245825, -0.91660675, -0.78468664,\n",
            "          0.19010413,  0.05963472, -0.16238514, -0.3291843 ,  0.24503886,\n",
            "         -0.12371715],\n",
            "        [ 0.47176421,  0.03607282,  0.1577172 ,  0.29071019,  0.98044854,\n",
            "          0.63971639, -0.17359813,  0.75253531,  0.64751887, -0.89105098,\n",
            "          0.43727447],\n",
            "        [ 0.60434112,  0.47281329,  0.4182635 ,  0.08187371, -0.75035165,\n",
            "          0.91529459, -0.1934874 , -0.56609768,  0.43455169,  0.98841488,\n",
            "         -0.48877189]])]\n",
            "Epoch 5\n",
            "Training Accuracy:0.6842105263157895\n",
            "Validation Accuracy:0.6153846153846154\n",
            "Epoch 10\n",
            "Training Accuracy:0.6842105263157895\n",
            "Validation Accuracy:0.6153846153846154\n",
            "Epoch 15\n",
            "Training Accuracy:0.6842105263157895\n",
            "Validation Accuracy:0.6153846153846154\n",
            "Epoch 20\n",
            "Training Accuracy:0.7456140350877193\n",
            "Validation Accuracy:0.7692307692307693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLFNC5ZGm3EG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd85aea-73a8-46e0-c665-69ceb8231f3d"
      },
      "source": [
        "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))"
      ],
      "execution_count": 1203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.7391304347826086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSSV-S0lJYoX"
      },
      "source": [
        "#Results\r\n",
        "##20 epochs\r\n",
        "###For 2 nodes in hidden layer we have \r\n",
        "Training Accuracy:0.9561<BR>\r\n",
        "Validation Accuracy:0.8461<BR>\r\n",
        "Testing Accuracy: 0.9130<br>\r\n",
        "###For 5 nodes in hidden layer we have \r\n",
        "Training Accuracy:0.9824<br>\r\n",
        "Validation Accuracy:0.9230<br>\r\n",
        "Testing Accuracy: 0.9565<br>\r\n",
        "###For 10 nodes in hidden layer we have \r\n",
        "Training Accuracy:0.7456<br>\r\n",
        "Validation Accuracy:0.7692<br>\r\n",
        "Testing Accuracy: 0.7391<br>\r\n",
        "#Conclusion\r\n",
        "####As we expected the model performs better than the linear-perceptron(ex_2a) since it combines the hidden layer's outputs to produce the final result.<br>Although the results are better our model still doesn't classify all the examples correctly no matter how many epochs we chose to run it for.This may be due to the dataset needing more hidden layers or outliers <br>Also, if we increase the number of nodes in the hidden layer too much its possible that our model will overfit and our accuracy will decrease.<br>\r\n",
        "\r\n"
      ]
    }
  ]
}